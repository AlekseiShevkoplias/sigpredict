{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import json\n",
    "import shutil\n",
    "import glob\n",
    "import itertools \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.tensorboard as tb\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimaDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 genome_file,\n",
    "                 y_file,\n",
    "                 window = 501, \n",
    "                 n_sequences = 10000\n",
    "                ):\n",
    "        self.genome_file = genome_file\n",
    "        self.y_file = y_file\n",
    "        self.window = window\n",
    "        self.n_sequences = n_sequences\n",
    "        self.order = np.random.permutation(n_sequences)\n",
    "        if window is None:\n",
    "            window = 501\n",
    "    def __len__(self):\n",
    "        return self.n_sequences\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.order[idx]\n",
    "        genome = np.memmap(self.genome_file, \n",
    "                           dtype='float32', mode='r', \n",
    "                           shape=(4,self.n_sequences*self.window)\n",
    "                          )\n",
    "        encoseq = np.zeros((4, self.window), dtype='float32')\n",
    "        \n",
    "        encoseq[:] = genome[:4,(self.window*idx):self.window*(idx+1)]\n",
    "        ys = np.memmap(self.y_file, \n",
    "                           dtype='float32', mode='r', \n",
    "                           shape=(self.n_sequences)\n",
    "                          )\n",
    "        signal = float(ys[idx])\n",
    "        return torch.Tensor(encoseq).view(4, -1), torch.FloatTensor([signal])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass BeerDataset(Dataset):\\n    def __init__(self,\\n                 genome_file,\\n                 y_file,\\n                 window = 500, \\n                 n_sequences = 10000\\n                ):\\n        self.genome_file = genome_file\\n        self.y_file = y_file\\n        self.window = window\\n        self.n_sequences = n_sequences\\n        self.order = np.random.permutation(n_sequences)\\n        if window is None:\\n            window = 500\\n    def __len__(self):\\n        return self.n_sequences\\n    def __getitem__(self, idx):\\n        idx = self.order[idx]\\n        genome = np.memmap(self.genome_file, \\n                           dtype='float32', mode='r', \\n                           shape=(4,self.n_sequences*self.window)\\n                          )\\n        encoseq = np.zeros((4, self.window), dtype='float32')\\n        \\n        encoseq[:] = genome[:4,(self.window*idx):self.window*(idx+1)]\\n        ys = np.memmap(self.y_file, \\n                           dtype='float32', mode='r', \\n                           shape=(self.n_sequences)\\n                          )\\n        signal = float(ys[idx])\\n        return torch.Tensor(encoseq).view(4, -1), torch.FloatTensor([signal])\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class BeerDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 genome_file,\n",
    "                 y_file,\n",
    "                 window = 500, \n",
    "                 n_sequences = 10000\n",
    "                ):\n",
    "        self.genome_file = genome_file\n",
    "        self.y_file = y_file\n",
    "        self.window = window\n",
    "        self.n_sequences = n_sequences\n",
    "        self.order = np.random.permutation(n_sequences)\n",
    "        if window is None:\n",
    "            window = 500\n",
    "    def __len__(self):\n",
    "        return self.n_sequences\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.order[idx]\n",
    "        genome = np.memmap(self.genome_file, \n",
    "                           dtype='float32', mode='r', \n",
    "                           shape=(4,self.n_sequences*self.window)\n",
    "                          )\n",
    "        encoseq = np.zeros((4, self.window), dtype='float32')\n",
    "        \n",
    "        encoseq[:] = genome[:4,(self.window*idx):self.window*(idx+1)]\n",
    "        ys = np.memmap(self.y_file, \n",
    "                           dtype='float32', mode='r', \n",
    "                           shape=(self.n_sequences)\n",
    "                          )\n",
    "        signal = float(ys[idx])\n",
    "        return torch.Tensor(encoseq).view(4, -1), torch.FloatTensor([signal])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorSimple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Conv1 = nn.Conv1d(in_channels=4, out_channels=128, kernel_size=8)\n",
    "        self.Conv2 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=8)\n",
    "        self.Conv3 = nn.Conv1d(in_channels=128, out_channels=1, kernel_size=4)\n",
    "        self.Maxpool = nn.MaxPool1d(kernel_size=4)\n",
    "        self.Linear1 = nn.Linear(26, 8)\n",
    "        self.Linear2 = nn.Linear(8, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.Conv1(x)\n",
    "        res = F.leaky_relu(res)\n",
    "        res = self.Maxpool(res)\n",
    "        res = self.Conv2(res)\n",
    "        res = F.leaky_relu(res)\n",
    "        res = self.Maxpool(res)\n",
    "        res = self.Conv3(res)\n",
    "        res = F.leaky_relu(res)\n",
    "\n",
    "        res = res.view(res.shape[0], -1)\n",
    "        res = self.Linear1(res)\n",
    "        res = F.leaky_relu(res)\n",
    "        res = self.Linear2(res)\n",
    "        res = F.sigmoid(res)\n",
    "\n",
    "\n",
    "\n",
    "        res = res.view(-1)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 0.0006\n",
    "base_lr = max_lr / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TAG=\"Major_HepG2_balancedGC_final\"#\"model_class_4\"\n",
    "drpr = \"NEWpreprocessed_HepG2_dataset/\"\n",
    "drys = \"NEWys_HepG2_dataset/\"\n",
    "\n",
    "np.random.seed(777)\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\")\n",
    "model = MajorSimple()\n",
    "model = model.to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.RMSprop(params=model.parameters(), lr=max_lr * 4)\n",
    "b = DimaDataset(genome_file = drpr + \\\n",
    "        '34959preprocessed_HepG2_positive.dat', \n",
    "        y_file = drys + '34959ys_HepG2_positive.dat', n_sequences = 34959)\n",
    "dl = DataLoader(b, batch_size=32, num_workers=4, shuffle=False)\n",
    "\n",
    "#bn = DimaDataset(genome_file =  drpr + \\\n",
    "#       '187127preprocessed_HepG2_negative.dat', \n",
    "#        y_file = drys + '187127ys_HepG2_negative.dat', n_sequences = 187127)\n",
    "#dln = DataLoader(bn, batch_size=32, num_workers=4, shuffle=False)\n",
    "\n",
    "bn = DimaDataset(genome_file = \"data/negative_sample/35194preprocessed_convertedHepG2_negative_sample_final.dat\", \n",
    "        y_file = \"data/negative_sample/35194ys_convertedHepG2_negative_sample_final.dat\", n_sequences = 35194)\n",
    "dln = DataLoader(bn, batch_size=32, num_workers=4, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "DIR_PATH = 'models_tb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = min(len(dl), len(dln)) * 4 // 5\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SummaryWriter(os.path.join(DIR_PATH, f\"{MODEL_TAG}_{VERSION}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_STEP = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join('models', MODEL_TAG + str(VERSION))\n",
    "os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 100):\n",
    "    it = iter(enumerate(zip(dl, dln)))\n",
    "    for i, ((px, _), (nx, _)) in it:\n",
    "        py = torch.ones(px.shape[0])\n",
    "        ny = torch.zeros(nx.shape[0])\n",
    "        py = py.view(ny.shape[0])\n",
    "        ny = ny.view(ny.shape[0])\n",
    "\n",
    "        x = torch.cat([px, nx]).to(device)\n",
    "        y = torch.cat([py, ny]).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        sm.add_scalar('train', loss.item(), GLOBAL_STEP)\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        GLOBAL_STEP += 1\n",
    "        #scheduler.step()\n",
    "\n",
    "        if i == train_end:\n",
    "            break\n",
    "    scheduler.step()   \n",
    "    total_loss = 0.00\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        n = 0\n",
    "        for i, ((px, _), (nx, _)) in it:\n",
    "            py = torch.ones(px.shape[0])\n",
    "            ny = torch.zeros(nx.shape[0])\n",
    "            py = py.view(py.shape[0])\n",
    "            ny = ny.view(ny.shape[0])\n",
    "            x = torch.cat([px, nx]).to(device)\n",
    "            y = torch.cat([py, ny]).to(device)\n",
    "            y_pred = model(x)\n",
    "            y_round = y_pred.round()\n",
    "            correct += y_round.eq(y.data.view_as(y)).cpu().sum().item()\n",
    "            n += y_pred.shape[0]\n",
    "            loss = loss_fn(y_pred,y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    sm.add_scalar ('accuracy', correct/n, GLOBAL_STEP)\n",
    "    total_loss /= (i - train_end)\n",
    "    sm.add_scalar('test', total_loss, GLOBAL_STEP)\n",
    "\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        path = os.path.join(model_dir, f\"model_{epoch}\")\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "        path = os.path.join(model_dir, f\"optimizer_{epoch}\")\n",
    "        torch.save(optimizer.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
